{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8SCzCtmv5nJC"
      },
      "outputs": [],
      "source": [
        "!pip install openpyxl python-docx pytesseract pdfplumber PyMuPDF together pandas matplotlib seaborn --quiet\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import docx\n",
        "import pytesseract\n",
        "import fitz\n",
        "import pdfplumber\n",
        "import together\n",
        "from PIL import Image\n",
        "from IPython.display import display\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade together\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdm681Eo8UZZ",
        "outputId": "466569af-a6b7-4a10-b836-2b0827c82d4a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: together in /usr/local/lib/python3.11/dist-packages (1.5.13)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.11.15)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.1.8)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from together) (0.2.2)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (2.0.2)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.2.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.11.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.11/dist-packages (from together) (0.15.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (2.19.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.8.1->together) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import together\n",
        "together.api_key = \"aa861f3c6f46676f129784fb1c81c71707c596ab7dc2512144051c8a559347e6\"\n",
        "together.Models.list()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkYjcRqq6TkC",
        "outputId": "06d9a804-dccc-4c97-86d0-e21ed7879d8c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-751122841>:3: DeprecationWarning: Call to deprecated function list.\n",
            "  together.Models.list()\n",
            "/usr/local/lib/python3.11/dist-packages/together/legacy/models.py:18: UserWarning: The use of together.api_key is deprecated and will be removed in the next major release. Please set the TOGETHER_API_KEY environment variable instead.\n",
            "  warnings.warn(API_KEY_WARNING)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'Alibaba-NLP/gte-modernbert-base',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1747292078,\n",
              "  'type': <ModelType.EMBEDDING: 'embedding'>,\n",
              "  'display_name': 'Gte Modernbert Base',\n",
              "  'organization': 'Alibaba Nlp',\n",
              "  'link': 'https://huggingface.co/api/models/Alibaba-NLP/gte-modernbert-base',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.08,\n",
              "   'output': 0.08,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': ['[PAD]'],\n",
              "   'bos_token': '[PAD]',\n",
              "   'eos_token': '[PAD]'}},\n",
              " {'id': 'arcee-ai/arcee-blitz',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1743449087,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Arcee AI Blitz',\n",
              "  'organization': 'Arcee AI',\n",
              "  'link': 'https://huggingface.co/api/models/togethercomputer/Arcee-Blitz',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.45,\n",
              "   'output': 0.75,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- set today = strftime_now(\"%Y-%m-%d\") %}\\n{%- set default_system_message = \"You are Arcee Blitz, a Large Language Model (LLM) created by Arcee AI.\\\\nYour knowledge base was last updated on 2024-10-01. The current date is \" + today + \".\\\\n\\\\nWhen you\\'re not sure about some information, you say that you don\\'t have the information and don\\'t make up anything.\\\\nIf the user\\'s question is not clear, ambiguous, or does not provide enough context for you to accurately answer the question, you do not try to answer it right away and you rather ask the user to clarify their request (e.g. \\\\\"What are some good restaurants around me?\\\\\" => \\\\\"Where are you?\\\\\" or \\\\\"When is the next flight to Tokyo\\\\\" => \\\\\"Where do you travel from?\\\\\")\" %}\\n\\n{{- bos_token }}\\n\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\'] %}\\n    {%- set loop_messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = default_system_message %}\\n    {%- set loop_messages = messages %}\\n{%- endif %}\\n{{- \\'[SYSTEM_PROMPT]\\' + system_message + \\'[/SYSTEM_PROMPT]\\' }}\\n\\n{%- for message in loop_messages %}\\n    {%- if message[\\'role\\'] == \\'user\\' %}\\n        {{- \\'[INST]\\' + message[\\'content\\'] + \\'[/INST]\\' }}\\n    {%- elif message[\\'role\\'] == \\'system\\' %}\\n        {{- \\'[SYSTEM_PROMPT]\\' + message[\\'content\\'] + \\'[/SYSTEM_PROMPT]\\' }}\\n    {%- elif message[\\'role\\'] == \\'assistant\\' %}\\n        {{- message[\\'content\\'] + eos_token }}\\n    {%- else %}\\n        {{- raise_exception(\\'Only user, system and assistant roles are supported!\\') }}\\n    {%- endif %}\\n{%- endfor %}',\n",
              "   'stop': ['</s>'],\n",
              "   'bos_token': '<s>',\n",
              "   'eos_token': '</s>'}},\n",
              " {'id': 'arcee-ai/caller',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1743531347,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Arcee AI Caller',\n",
              "  'organization': 'Arcee AI',\n",
              "  'link': 'https://huggingface.co/api/models/togethercomputer/arcee-ai-caller',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.55,\n",
              "   'output': 0.85,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': ['<|im_end|>'],\n",
              "   'bos_token': '<|endoftext|>',\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'arcee-ai/coder-large',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1745522718,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Arcee AI Coder-Large',\n",
              "  'organization': 'Arcee AI',\n",
              "  'link': 'https://huggingface.co/api/models/togethercomputer/arcee-ai-coder-large',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.5,\n",
              "   'output': 0.8,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are Coder Large, created by Arcee AI. You are a helpful coding assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|im_end|>'],\n",
              "   'bos_token': '<|endoftext|>',\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'arcee-ai/maestro-reasoning',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1743527998,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Arcee AI Maestro',\n",
              "  'organization': 'Arcee AI',\n",
              "  'link': 'https://huggingface.co/api/models/togethercomputer/arcee-ai-maestro-32b-01',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.9,\n",
              "   'output': 3.3,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n  {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" and not message.tool_calls %}\\n        {%- set content = message.content %}\\n        {%- if not loop.last %}\\n            {%- set content = message.content.split(\\'</think>\\')[-1].lstrip(\\'\\\\n\\') %}\\n        {%- endif %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {%- set content = message.content %}\\n        {%- if not loop.last %}\\n            {%- set content = message.content.split(\\'</think>\\')[-1].lstrip(\\'\\\\n\\') %}\\n        {%- endif %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n<think>\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|im_end|>'],\n",
              "   'bos_token': '<|endoftext|>',\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'arcee-ai/virtuoso-large',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1745522892,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Arcee AI Virtuoso-Large',\n",
              "  'organization': 'Arcee AI',\n",
              "  'link': 'https://huggingface.co/api/models/togethercomputer/arcee-ai-Virtuoso-Large',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.75,\n",
              "   'output': 1.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are Virtuoso Large, created by Arcee AI. You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|im_end|>'],\n",
              "   'bos_token': '<|endoftext|>',\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'arcee-ai/virtuoso-medium-v2',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1743430178,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Arcee AI Virtuoso-Medium',\n",
              "  'organization': 'Arcee AI',\n",
              "  'link': 'https://huggingface.co/api/models/togethercomputer/Virtuoso-Medium-v2',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.5,\n",
              "   'output': 0.8,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are Virtuoso Medium, created by Arcee AI. You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|im_end|>'],\n",
              "   'bos_token': '<|endoftext|>',\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'arcee_ai/arcee-spotlight',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1743530644,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Arcee AI Spotlight',\n",
              "  'organization': 'Arcee AI',\n",
              "  'link': 'https://huggingface.co/api/models/togethercomputer/arcee-ai-spotlight-export',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.18000000000000002,\n",
              "   'output': 0.18000000000000002,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|im_end|>'],\n",
              "   'bos_token': '<|endoftext|>',\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'BAAI/bge-base-en-v1.5-vllm',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1749585052,\n",
              "  'type': <ModelType.EMBEDDING: 'embedding'>,\n",
              "  'display_name': 'BAAI-Bge-Base-1.5',\n",
              "  'link': 'https://huggingface.co/api/models/BAAI/bge-base-en-v1.5',\n",
              "  'license': 'MIT',\n",
              "  'context_length': 512,\n",
              "  'pricing': {'input': 0.008,\n",
              "   'output': 0.008,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': '[PAD]',\n",
              "   'eos_token': None}},\n",
              " {'id': 'black-forest-labs/FLUX.1-canny',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1732144835,\n",
              "  'type': <ModelType.IMAGE: 'image'>,\n",
              "  'display_name': 'FLUX.1 Canny [dev]',\n",
              "  'organization': 'Black Forest Labs',\n",
              "  'link': 'https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev',\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'black-forest-labs/FLUX.1-depth',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1732141533,\n",
              "  'type': <ModelType.IMAGE: 'image'>,\n",
              "  'display_name': 'FLUX.1 Depth [dev]',\n",
              "  'organization': 'Black Forest Labs',\n",
              "  'link': 'https://huggingface.co/black-forest-labs/FLUX.1-Depth-dev',\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'black-forest-labs/FLUX.1-dev',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1732138026,\n",
              "  'type': <ModelType.IMAGE: 'image'>,\n",
              "  'display_name': 'FLUX.1 [dev]',\n",
              "  'organization': 'Black Forest Labs',\n",
              "  'link': 'https://huggingface.co/black-forest-labs/FLUX.1-dev',\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'black-forest-labs/FLUX.1-dev-lora',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1736906515,\n",
              "  'type': <ModelType.IMAGE: 'image'>,\n",
              "  'display_name': 'FLUX.1 [dev] LoRA',\n",
              "  'organization': 'Black Forest Labs',\n",
              "  'link': 'https://huggingface.co/black-forest-labs/FLUX.1-dev',\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'black-forest-labs/FLUX.1-kontext-max',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 0,\n",
              "  'type': <ModelType.IMAGE: 'image'>,\n",
              "  'display_name': 'FLUX.1 Kontext [max]',\n",
              "  'context_length': 0,\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'black-forest-labs/FLUX.1-kontext-pro',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 0,\n",
              "  'type': <ModelType.IMAGE: 'image'>,\n",
              "  'display_name': 'FLUX.1 Kontext [pro]',\n",
              "  'context_length': 0,\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'black-forest-labs/FLUX.1-pro',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 0,\n",
              "  'type': <ModelType.IMAGE: 'image'>,\n",
              "  'display_name': 'FLUX.1 [pro]',\n",
              "  'organization': 'Black Forest Labs',\n",
              "  'link': 'https://huggingface.co/black-forest-labs/FLUX.1-schnell',\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'black-forest-labs/FLUX.1-redux',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1732148338,\n",
              "  'type': <ModelType.IMAGE: 'image'>,\n",
              "  'display_name': 'FLUX.1 Redux [dev]',\n",
              "  'organization': 'Black Forest Labs',\n",
              "  'link': 'https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev',\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'black-forest-labs/FLUX.1-schnell',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 0,\n",
              "  'type': <ModelType.IMAGE: 'image'>,\n",
              "  'display_name': 'FLUX.1 Schnell',\n",
              "  'organization': 'Black Forest Labs',\n",
              "  'link': 'https://huggingface.co/black-forest-labs/FLUX.1-schnell',\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'black-forest-labs/FLUX.1-schnell-Free',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 0,\n",
              "  'type': <ModelType.IMAGE: 'image'>,\n",
              "  'display_name': 'FLUX.1 [schnell] Free',\n",
              "  'organization': 'Black Forest Labs',\n",
              "  'link': 'https://huggingface.co/black-forest-labs/FLUX.1-schnell',\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'black-forest-labs/FLUX.1.1-pro',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 0,\n",
              "  'type': <ModelType.IMAGE: 'image'>,\n",
              "  'display_name': 'FLUX1.1 [pro]',\n",
              "  'organization': 'Black Forest Labs',\n",
              "  'link': 'https://huggingface.co/black-forest-labs/FLUX.1-schnell',\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'cartesia/sonic',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 0,\n",
              "  'type': <ModelType.AUDIO: 'audio'>,\n",
              "  'display_name': 'Cartesia Sonic',\n",
              "  'organization': 'Together',\n",
              "  'link': 'https://www.cartesia.ai',\n",
              "  'context_length': 0,\n",
              "  'pricing': {'input': 65.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'cartesia/sonic-2',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 0,\n",
              "  'type': <ModelType.AUDIO: 'audio'>,\n",
              "  'display_name': 'Cartesia Sonic 2',\n",
              "  'organization': 'Together',\n",
              "  'link': 'https://www.cartesia.ai',\n",
              "  'context_length': 0,\n",
              "  'pricing': {'input': 65.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'deepseek-ai/DeepSeek-R1',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1737396322,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'DeepSeek R1-0528',\n",
              "  'organization': 'DeepSeek',\n",
              "  'link': 'https://huggingface.co/deepseek-ai/DeepSeek-R1',\n",
              "  'context_length': 163840,\n",
              "  'pricing': {'input': 3.0,\n",
              "   'output': 7.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{%- for message in messages -%}{%- if message.role == 'system' -%}{{- message.content -}}{%- endif -%}{%- if message.role == 'user' -%}{{- message.content -}}{%- endif -%}{%- if message.role == 'assistant' -%}{{- message.content -}}{%- endif -%}{%- if message.role == 'tool' -%}{{- message.content -}}{%- endif -%}{%- endfor -%}\",\n",
              "   'stop': ['<｜end▁of▁sentence｜>'],\n",
              "   'bos_token': '<｜begin▁of▁sentence｜>',\n",
              "   'eos_token': '<｜end▁of▁sentence｜>',\n",
              "   'max_output_length': 32768}},\n",
              " {'id': 'deepseek-ai/DeepSeek-R1-Distill-Llama-70B',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1738048961,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'DeepSeek R1 Distill Llama 70B',\n",
              "  'organization': 'DeepSeek',\n",
              "  'link': 'https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B',\n",
              "  'license': 'mit',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 2.0,\n",
              "   'output': 2.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set system_prompt='' %}{% set is_tool = false %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set is_tool = false -%}{%- set is_output_first = true -%}{%- set is_first = false -%}{%- for tool in message['tool_calls']%}{%- if is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set is_first = true -%}{%- else %}{{'\\\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set parts = content | split('</think>') %}{% set content = parts[parts.length-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set is_tool = true -%}{%- if is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set is_output_first = false %}{%- else %}{{'\\\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not is_tool %}{{'<｜Assistant｜>'}}{% endif %}\",\n",
              "   'stop': ['<｜end▁of▁sentence｜>'],\n",
              "   'bos_token': '<｜begin▁of▁sentence｜>',\n",
              "   'eos_token': '<｜end▁of▁sentence｜>',\n",
              "   'max_output_length': 32768}},\n",
              " {'id': 'deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1738187359,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'DeepSeek R1 Distill Llama 70B Free',\n",
              "  'organization': 'DeepSeek',\n",
              "  'link': 'https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B',\n",
              "  'license': 'mit',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set system_prompt='' %}{% set is_tool = false %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set is_tool = false -%}{%- set is_output_first = true -%}{%- set is_first = false -%}{%- for tool in message['tool_calls']%}{%- if is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set is_first = true -%}{%- else %}{{'\\\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set parts = content | split('</think>') %}{% set content = parts[parts.length-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set is_tool = true -%}{%- if is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set is_output_first = false %}{%- else %}{{'\\\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not is_tool %}{{'<｜Assistant｜>'}}{% endif %}\",\n",
              "   'stop': ['<｜end▁of▁sentence｜>'],\n",
              "   'bos_token': '<｜begin▁of▁sentence｜>',\n",
              "   'eos_token': '<｜end▁of▁sentence｜>'}},\n",
              " {'id': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1738185844,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'DeepSeek R1 Distill Qwen 1.5B',\n",
              "  'organization': 'DeepSeek',\n",
              "  'link': 'https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B',\n",
              "  'license': 'mit',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.18000000000000002,\n",
              "   'output': 0.18000000000000002,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% if not add_generation_prompt %}{% set add_generation_prompt = false %}{% endif %}{# Initialize variables since Nunjucks doesn't support namespace #}{% set is_first = false %}{% set is_tool = false %}{% set is_output_first = true %}{% set system_prompt = '' %}{# Get system prompt #}{% for message in messages %}{% if message.role == 'system' %}{% set system_prompt = message.content %}{% endif %}{% endfor %}{{bos_token}}{{system_prompt}}{% for message in messages %}{% if message.role == 'user' %}{% set is_tool = false %}<｜User｜>{{message.content}}{% endif %}{% if message.role == 'assistant' and not message.content %}{% set is_tool = false %}{% for tool in message.tool_calls %}{% if not is_first %}<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>{{tool.type}}<｜tool▁sep｜>{{tool.function.name}}```json{{tool.function.arguments}}```<｜tool▁call▁end｜>{% set is_first = true %}{% else %}<｜tool▁call▁begin｜>{{tool.type}}<｜tool▁sep｜>{{tool.function.name}}```json{{tool.function.arguments}}```<｜tool▁call▁end｜><｜tool▁calls▁end｜><｜end▁of▁sentence｜>{% endif %}{% endfor %}{% endif %}{% if message.role == 'assistant' and message.content %}{% if is_tool %}<｜tool▁outputs▁end｜>{{message.content}}<｜end▁of▁sentence｜>{% set is_tool = false %}{% else %}{% set content = message.content %}{% if '</think>' in content %}{% set parts = content | split('</think>') %}{% set content = parts[parts.length-1] %}{% endif %}<｜Assistant｜>{{content}}<｜end▁of▁sentence｜>{% endif %}{% endif %}{% if message.role == 'tool' %}{% set is_tool = true %}{% if is_output_first %}<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>{{message.content}}<｜tool▁output▁end｜>{% set is_output_first = false %}{% else %}<｜tool▁output▁begin｜>{{message.content}}<｜tool▁output▁end｜>{% endif %}{% endif %}{% endfor %}{% if is_tool %}<｜tool▁outputs▁end｜>{% endif %}{% if add_generation_prompt and not is_tool %}<｜Assistant｜>{% endif %}\",\n",
              "   'stop': ['<｜end▁of▁sentence｜>'],\n",
              "   'bos_token': '<｜begin▁of▁sentence｜>',\n",
              "   'eos_token': '<｜end▁of▁sentence｜>'}},\n",
              " {'id': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1738182549,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'DeepSeek R1 Distill Qwen 14B',\n",
              "  'organization': 'DeepSeek',\n",
              "  'link': 'https://huggingface.co/api/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B',\n",
              "  'license': 'mit',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 1.6,\n",
              "   'output': 1.6,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% if not add_generation_prompt %}{% set add_generation_prompt = false %}{% endif %}{# Initialize variables since Nunjucks doesn't support namespace #}{% set is_first = false %}{% set is_tool = false %}{% set is_output_first = true %}{% set system_prompt = '' %}{# Get system prompt #}{% for message in messages %}{% if message.role == 'system' %}{% set system_prompt = message.content %}{% endif %}{% endfor %}{{bos_token}}{{system_prompt}}{% for message in messages %}{% if message.role == 'user' %}{% set is_tool = false %}<｜User｜>{{message.content}}{% endif %}{% if message.role == 'assistant' and not message.content %}{% set is_tool = false %}{% for tool in message.tool_calls %}{% if not is_first %}<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>{{tool.type}}<｜tool▁sep｜>{{tool.function.name}}```json{{tool.function.arguments}}```<｜tool▁call▁end｜>{% set is_first = true %}{% else %}<｜tool▁call▁begin｜>{{tool.type}}<｜tool▁sep｜>{{tool.function.name}}```json{{tool.function.arguments}}```<｜tool▁call▁end｜><｜tool▁calls▁end｜><｜end▁of▁sentence｜>{% endif %}{% endfor %}{% endif %}{% if message.role == 'assistant' and message.content %}{% if is_tool %}<｜tool▁outputs▁end｜>{{message.content}}<｜end▁of▁sentence｜>{% set is_tool = false %}{% else %}{% set content = message.content %}{% if '</think>' in content %}{% set parts = content | split('</think>') %}{% set content = parts[parts.length-1] %}{% endif %}<｜Assistant｜>{{content}}<｜end▁of▁sentence｜>{% endif %}{% endif %}{% if message.role == 'tool' %}{% set is_tool = true %}{% if is_output_first %}<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>{{message.content}}<｜tool▁output▁end｜>{% set is_output_first = false %}{% else %}<｜tool▁output▁begin｜>{{message.content}}<｜tool▁output▁end｜>{% endif %}{% endif %}{% endfor %}{% if is_tool %}<｜tool▁outputs▁end｜>{% endif %}{% if add_generation_prompt and not is_tool %}<｜Assistant｜>{% endif %}\",\n",
              "   'stop': ['<｜end▁of▁sentence｜>'],\n",
              "   'bos_token': '<｜begin▁of▁sentence｜>',\n",
              "   'eos_token': '<｜end▁of▁sentence｜>',\n",
              "   'max_output_length': 32768}},\n",
              " {'id': 'deepseek-ai/DeepSeek-V3',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1735450433,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'DeepSeek V3-0324',\n",
              "  'organization': 'DeepSeek',\n",
              "  'link': 'https://huggingface.co/deepseek-ai/DeepSeek-V3',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 1.25,\n",
              "   'output': 1.25,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set is_first = false %}{% set is_tool = false %}{% set is_output_first = true %}{% set system_prompt=\\'\\' %}{% set is_first_sp = true %}{%- for message in messages %}{%- if message[\\'role\\'] == \\'system\\' %}{%- if is_first_sp %}{% set system_prompt = system_prompt + message[\\'content\\'] %}{% set is_first_sp = false %}{%- else %}{% set system_prompt = system_prompt + \\'\\n\\n\\' + message[\\'content\\'] %}{%- endif %}{%- endif %}{%- endfor %}{% if tools %}{% set system_prompt = system_prompt + \\'\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\\' + (tools | tojson) + \\'\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\"name\": <function-name>, \"arguments\": <args-json-object>}\\n</tool_call>\\n\\' %}{% endif %}{{bos_token}}{{system_prompt}}{%- for message in messages %}{%- if message[\\'role\\'] == \\'user\\' %}{%- set is_tool = false -%}{{\\'<｜User｜>\\' + message[\\'content\\']}}{%- endif %}{%- if message[\\'role\\'] == \\'assistant\\' and message[\\'content\\'] is none %}{%- set is_tool = false -%}{%- for tool in message[\\'tool_calls\\']%}{%- if not is_first %}{{\\'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>\\' + tool[\\'type\\'] + \\'<｜tool▁sep｜>\\' + tool[\\'function\\'][\\'name\\'] + \\'\\n\\' + \\'```json\\' + \\'\\n\\' + tool[\\'function\\'][\\'arguments\\'] + \\'\\n\\' + \\'```\\' + \\'<｜tool▁call▁end｜>\\'}}{%- set is_first = true -%}{%- else %}{{\\'\\n\\' + \\'<｜tool▁call▁begin｜>\\' + tool[\\'type\\'] + \\'<｜tool▁sep｜>\\' + tool[\\'function\\'][\\'name\\'] + \\'\\n\\' + \\'```json\\' + \\'\\n\\' + tool[\\'function\\'][\\'arguments\\'] + \\'\\n\\' + \\'```\\' + \\'<｜tool▁call▁end｜>\\'}}{{\\'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>\\'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message[\\'role\\'] == \\'assistant\\' and message[\\'content\\'] is not none %}{%- if is_tool %}{{\\'<｜tool▁outputs▁end｜>\\' + message[\\'content\\'] + \\'<｜end▁of▁sentence｜>\\'}}{%- set is_tool = false -%}{%- else %}{{\\'<｜Assistant｜>\\' + message[\\'content\\'] + \\'<｜end▁of▁sentence｜>\\'}}{%- endif %}{%- endif %}{%- if message[\\'role\\'] == \\'tool\\' %}{%- set is_tool = true -%}{%- if is_output_first %}{{\\'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>\\' + message[\\'content\\'] + \\'<｜tool▁output▁end｜>\\'}}{%- set is_output_first = false %}{%- else %}{{\\'\\n<｜tool▁output▁begin｜>\\' + message[\\'content\\'] + \\'<｜tool▁output▁end｜>\\'}}{%- endif %}{%- endif %}{%- endfor -%}{% if is_tool %}{{\\'<｜tool▁outputs▁end｜>\\'}}{% endif %}{% if add_generation_prompt and not is_tool %}{{\\'<｜Assistant｜>\\'}}{% endif %}',\n",
              "   'stop': ['<｜end▁of▁sentence｜>'],\n",
              "   'bos_token': '<｜begin▁of▁sentence｜>',\n",
              "   'eos_token': '<｜end▁of▁sentence｜>',\n",
              "   'max_output_length': 12288}},\n",
              " {'id': 'deepseek-ai/DeepSeek-V3-p-dp',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1740979667,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'DeepSeek V3',\n",
              "  'organization': 'DeepSeek',\n",
              "  'link': 'https://huggingface.co/deepseek-ai/DeepSeek-V3',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 1.25,\n",
              "   'output': 1.25,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set is_first = false %}{% set is_tool = false %}{% set is_output_first = true %}{% set system_prompt='' %}{% set is_first_sp = true %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if is_first_sp %}{% set system_prompt = system_prompt + message['content'] %}{% set is_first_sp = false %}{%- else %}{% set system_prompt = system_prompt + '\\n\\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{% if tools %}{% set system_prompt = system_prompt + '\\n\\nYou can access the following functions. Use them if required -\\n' + (tools | tojson) + '\\n' %}{% endif %}{{bos_token}}{{system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set is_tool = false -%}{%- else %}{{'<｜Assistant｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set is_tool = true -%}{%- if is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set is_output_first = false %}{%- else %}{{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not is_tool %}{{'<｜Assistant｜>'}}{% endif %}\",\n",
              "   'stop': ['<｜end▁of▁sentence｜>'],\n",
              "   'bos_token': '<｜begin▁of▁sentence｜>',\n",
              "   'eos_token': '<｜end▁of▁sentence｜>',\n",
              "   'max_output_length': 32768}},\n",
              " {'id': 'google/gemma-2-27b-it',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1708648606,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Gemma-2 Instruct (27B)',\n",
              "  'organization': 'Google',\n",
              "  'link': 'https://huggingface.co/google/gemma-2b-it',\n",
              "  'license': 'gemma-terms-of-use',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.8,\n",
              "   'output': 0.8,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\\n' + message['content'] | trim + '<end_of_turn>\\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{% endif %}\",\n",
              "   'stop': ['<eos>', '<end_of_turn>'],\n",
              "   'bos_token': '<bos>',\n",
              "   'eos_token': '<end_of_turn>'}},\n",
              " {'id': 'Gryphe/MythoMax-L2-13b',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1693943905,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'MythoMax-L2 (13B)',\n",
              "  'organization': 'Gryphe',\n",
              "  'license': 'other',\n",
              "  'context_length': 4096,\n",
              "  'pricing': {'input': 0.3,\n",
              "   'output': 0.3,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\",\n",
              "   'stop': ['</s>'],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'Gryphe/MythoMax-L2-13b-Lite',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1693943905,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Gryphe MythoMax L2 Lite (13B)',\n",
              "  'organization': 'Gryphe',\n",
              "  'license': 'other',\n",
              "  'context_length': 4096,\n",
              "  'pricing': {'input': 0.1,\n",
              "   'output': 0.1,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\",\n",
              "   'stop': ['</s>'],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'intfloat/multilingual-e5-large-instruct',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1745513588,\n",
              "  'type': <ModelType.EMBEDDING: 'embedding'>,\n",
              "  'display_name': 'Multilingual E5 Large Instruct',\n",
              "  'organization': 'Intfloat',\n",
              "  'link': 'https://huggingface.co/api/models/intfloat/multilingual-e5-large-instruct',\n",
              "  'license': 'mit',\n",
              "  'context_length': 514,\n",
              "  'pricing': {'input': 0.02,\n",
              "   'output': 0.02,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': ['</s>'],\n",
              "   'bos_token': '<s>',\n",
              "   'eos_token': '</s>'}},\n",
              " {'id': 'lgai/exaone-3-5-32b-instruct',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1743446196,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'EXAONE 3.5 32B Instruct',\n",
              "  'organization': 'LG AI',\n",
              "  'link': 'https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-32B-Instruct',\n",
              "  'license': 'other exaone',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{{ '[|' + message['role'] + '|]' + message['content'] }}{% if message['role'] == 'user' %}{{ '\\n' }}{% else %}{{ '[|endofturn|]\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '[|assistant|]' }}{% endif %}\",\n",
              "   'stop': ['[|endofturn|]'],\n",
              "   'bos_token': '[BOS]',\n",
              "   'eos_token': '[|endofturn|]'}},\n",
              " {'id': 'lgai/exaone-deep-32b',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1748542032,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'EXAONE Deep 32B',\n",
              "  'organization': 'LG AI',\n",
              "  'link': 'https://huggingface.co/LGAI-EXAONE/EXAONE-Deep-32B',\n",
              "  'license': 'exaone',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': ['[|endofturn|]', '[EOS]'],\n",
              "   'bos_token': '[BOS]',\n",
              "   'eos_token': '[|endofturn|]'}},\n",
              " {'id': 'marin-community/marin-8b-instruct',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1747581847,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Marin 8B Instruct',\n",
              "  'organization': 'Marin Community',\n",
              "  'link': 'https://huggingface.co/api/models/marin-community/marin-8b-instruct',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.18000000000000002,\n",
              "   'output': 0.18000000000000002,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': ['<|eot_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'meta-llama-llama-2-70b-hf',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1736983494,\n",
              "  'type': <ModelType.LANGUAGE: 'language'>,\n",
              "  'display_name': 'LLaMA-2 (70B)',\n",
              "  'link': 'https://huggingface.co/api/models/meta-llama/Llama-2-70b-hf',\n",
              "  'license': 'llama2',\n",
              "  'context_length': 4096,\n",
              "  'pricing': {'input': 0.9,\n",
              "   'output': 0.9,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': ['</s>'],\n",
              "   'bos_token': '<s>',\n",
              "   'eos_token': '</s>'}},\n",
              " {'id': 'meta-llama/Llama-2-70b-hf',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1689720415,\n",
              "  'type': <ModelType.LANGUAGE: 'language'>,\n",
              "  'display_name': 'LLaMA-2 (70B)',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/api/models/meta-llama/Llama-2-70b-hf',\n",
              "  'license': 'llama2',\n",
              "  'context_length': 4096,\n",
              "  'pricing': {'input': 0.9,\n",
              "   'output': 0.9,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': ['</s>'],\n",
              "   'bos_token': '<s>',\n",
              "   'eos_token': '</s>'}},\n",
              " {'id': 'meta-llama/Llama-3-70b-chat-hf',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1713429236,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama 3 70B Instruct Reference',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct',\n",
              "  'license': 'Llama-3 (Other)',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.88,\n",
              "   'output': 0.88,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\",\n",
              "   'stop': ['<|eot_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|end_of_text|>'}},\n",
              " {'id': 'meta-llama/Llama-3-8b-chat-hf',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1713420479,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama 3 8B Instruct Reference',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct',\n",
              "  'license': 'Llama-3 (Other)',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.2,\n",
              "   'output': 0.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\",\n",
              "   'stop': ['<|eot_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|end_of_text|>'}},\n",
              " {'id': 'meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1727218691,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama 3.2 11B Vision Instruct Turbo',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct',\n",
              "  'license': 'llama',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.18000000000000002,\n",
              "   'output': 0.18000000000000002,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{% for message in messages %}\\n{% if loop.index0 == 0 %}{{ bos_token }}{% endif %}\\n{{ \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\' }}\\n{% if message[\\'content\\'] is string %}\\n{{ message[\\'content\\'] }}\\n{% else %}\\n{% for content in message[\\'content\\'] | sort(attribute=\"type\") %}\\n{% if content[\\'type\\'] == \\'image\\' %}\\n{{ \\'<|image|>\\' }}\\n{% elif content[\\'type\\'] == \\'text\\' %}\\n{{ content[\\'text\\'] }}\\n{% endif %}\\n{% endfor %}\\n{% endif %}\\n{{ \\'<|eot_id|>\\' }}\\n{% endfor %}\\n{% if add_generation_prompt %}\\n{{ \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{% endif %}',\n",
              "   'stop': ['<|eot_id|>', '<|eom_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'meta-llama/Llama-3.2-3B-Instruct-Turbo',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1727229064,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama 3.2 3B Instruct Turbo',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct',\n",
              "  'license': 'Llama-3.1 (Other)',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.060000000000000005,\n",
              "   'output': 0.060000000000000005,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|eot_id|>', '<|eom_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1727227657,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama 3.2 90B Vision Instruct Turbo',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Llama-3.2-90B-Vision-Instruct',\n",
              "  'license': 'llama',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 1.2,\n",
              "   'output': 1.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{% for message in messages %}\\n{% if loop.index0 == 0 %}{{ bos_token }}{% endif %}\\n{{ \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\' }}\\n{% if message[\\'content\\'] is string %}\\n{{ message[\\'content\\'] }}\\n{% else %}\\n{% for content in message[\\'content\\'] | sort(attribute=\"type\") %}\\n{% if content[\\'type\\'] == \\'image\\' %}\\n{{ \\'<|image|>\\' }}\\n{% elif content[\\'type\\'] == \\'text\\' %}\\n{{ content[\\'text\\'] }}\\n{% endif %}\\n{% endfor %}\\n{% endif %}\\n{{ \\'<|eot_id|>\\' }}\\n{% endfor %}\\n{% if add_generation_prompt %}\\n{{ \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{% endif %}',\n",
              "   'stop': ['<|eot_id|>', '<|eom_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'meta-llama/Llama-3.3-70B-Instruct-Turbo',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1733466629,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama 3.3 70B Instruct Turbo',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct',\n",
              "  'license': 'Llama-3.3 (Other)',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.88,\n",
              "   'output': 0.88,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \"Tools: \" + builtin_tools | reject(\\'equalto\\', \\'code_interpreter\\') | join(\", \") + \"\\\\n\\\\n\"}}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + \\'=\"\\' + arg_val + \\'\"\\' }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \")\" }}\\n        {%- else  %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n            {{- \\'\"parameters\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \"}\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we\\'re in ipython mode #}\\n            {{- \"<|eom_id|>\" }}\\n        {%- else %}\\n            {{- \"<|eot_id|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|eot_id|>', '<|eom_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'meta-llama/Llama-3.3-70B-Instruct-Turbo-Free',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1733967427,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama 3.3 70B Instruct Turbo Free',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct',\n",
              "  'license': 'Llama-3.3 (Other)',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \"Tools: \" + builtin_tools | reject(\\'equalto\\', \\'code_interpreter\\') | join(\", \") + \"\\\\n\\\\n\"}}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + \\'=\"\\' + arg_val + \\'\"\\' }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \")\" }}\\n        {%- else  %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n            {{- \\'\"parameters\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \"}\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we\\'re in ipython mode #}\\n            {{- \"<|eom_id|>\" }}\\n        {%- else %}\\n            {{- \"<|eot_id|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|eot_id|>', '<|eom_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1743878353,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Llama 4 Maverick Instruct (17Bx128E)',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8',\n",
              "  'license': 'llama4',\n",
              "  'context_length': 1048576,\n",
              "  'pricing': {'input': 0.27,\n",
              "   'output': 0.85,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- if messages[0][\\'content\\'] is string %}\\n        {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- else %}\\n        {#- FIXME: The processor requires an array, always. #}\\n        {%- set system_message = messages[0][\\'content\\'][0][\\'text\\']|trim %}\\n    {%- endif %}\\n    {%- set messages = messages[1:] %}\\n    {%- set user_supplied_system_message = true %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n    {%- set user_supplied_system_message = false %}\\n{%- endif %}\\n\\n{#- System message if the user supplied one #}\\n{%- if user_supplied_system_message %}\\n    {{- \"<|header_start|>system<|header_end|>\\\\n\\\\n\" }}\\n    {%- if tools is not none %}\\n        {{- \"Environment: ipython\\\\n\" }}\\n    {%- endif %}\\n    {%- if tools is not none and not tools_in_user_message %}\\n        {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n        {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n        {{- \"Do not use variables.\\\\n\\\\n\" }}\\n        {%- for t in tools %}\\n            {{- t | tojson(indent=4) }}\\n            {{- \"\\\\n\\\\n\" }}\\n        {%- endfor %}\\n    {%- endif %}\\n    {{- system_message }}\\n    {{- \"<|eot|>\" }}\\n{%- endif %}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_content = messages[0][\\'content\\'] %}\\n        {%- set first_user_message = \"\" %}\\n        {%- if first_content is string %}\\n            {%- set first_user_message = first_content %}\\n        {%- else %}\\n            {%- for content in first_content %}\\n                {%- if content[\\'type\\'] == \\'image\\' %}\\n                    {%- set first_user_message = first_user_message + \\'<|image|>\\' %}\\n                {%- elif content[\\'type\\'] == \\'text\\' %}\\n                    {%- set first_user_message = first_user_message + content[\\'text\\'] %}\\n                {%- endif %}\\n            {%- endfor %}\\n        {%- endif %}\\n        {%- set first_user_message = first_user_message | trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|header_start|>user<|header_end|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n    {{- \\'<|header_start|>\\' + message[\\'role\\'] + \\'<|header_end|>\\\\n\\\\n\\' }}\\n        {%- if message[\\'content\\'] is string %}\\n            {{- message[\\'content\\'] }}\\n        {%- else %}\\n            {%- for content in message[\\'content\\'] %}\\n                {%- if content[\\'type\\'] == \\'image\\' %}\\n                    {{- \\'<|image|>\\' }}\\n                {%- elif content[\\'type\\'] == \\'text\\' %}\\n                    {{- content[\\'text\\'] }}\\n                {%- endif %}\\n            {%- endfor %}\\n        {%- endif %}\\n        {{- \"<|eot|>\" }}\\n    {%- elif \\'tool_calls\\' in message and message.tool_calls|length > 0 %}\\n      {{- \\'<|header_start|>assistant<|header_end|>\\\\n\\\\n\\' -}}\\n      {{- \\'<|python_start|>\\' }}\\n        {%- if message[\\'content\\'] is string %}\\n            {{- message[\\'content\\'] }}\\n        {%- else %}\\n            {%- for content in message[\\'content\\'] %}\\n                {%- if content[\\'type\\'] == \\'image\\' %}\\n                    {{- \\'<|image|>\\' }}\\n                {%- elif content[\\'type\\'] == \\'text\\' %}\\n                    {{- content[\\'text\\'] }}\\n                {%- endif %}\\n            {%- endfor %}\\n        {%- endif %}\\n      {{- \\'<|python_end|>\\' }}\\n        {%- for tool_call in message.tool_calls %}\\n          {{- \\'{\"name\": \"\\' + tool_call.function.name + \\'\", \\' }}\\n          {{- \\'\"parameters\": \\' }}\\n          {{- tool_call.function.arguments | tojson }}\\n          {{- \"}\" }}\\n        {%- endfor %}\\n      {{- \"<|eot|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|header_start|>ipython<|header_end|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|header_start|>assistant<|header_end|>\\\\n\\\\n\\' }}\\n{%- endif %}',\n",
              "   'stop': ['<|eot|>', '<|eom|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot|>',\n",
              "   'max_output_length': 32768}},\n",
              " {'id': 'meta-llama/Llama-4-Scout-17B-16E-Instruct',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1743878170,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Llama 4 Scout Instruct (17Bx16E)',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct',\n",
              "  'license': 'llama4',\n",
              "  'context_length': 1048576,\n",
              "  'pricing': {'input': 0.18000000000000002,\n",
              "   'output': 0.5900000000000001,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- if messages[0][\\'content\\'] is string %}\\n        {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- else %}\\n        {#- FIXME: The processor requires an array, always. #}\\n        {%- set system_message = messages[0][\\'content\\'][0][\\'text\\']|trim %}\\n    {%- endif %}\\n    {%- set messages = messages[1:] %}\\n    {%- set user_supplied_system_message = true %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n    {%- set user_supplied_system_message = false %}\\n{%- endif %}\\n\\n{#- System message if the user supplied one #}\\n{%- if user_supplied_system_message %}\\n    {{- \"<|header_start|>system<|header_end|>\\\\n\\\\n\" }}\\n    {%- if tools is not none %}\\n        {{- \"Environment: ipython\\\\n\" }}\\n    {%- endif %}\\n    {%- if tools is not none and not tools_in_user_message %}\\n        {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n        {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n        {{- \"Do not use variables.\\\\n\\\\n\" }}\\n        {%- for t in tools %}\\n            {{- t | tojson(indent=4) }}\\n            {{- \"\\\\n\\\\n\" }}\\n        {%- endfor %}\\n    {%- endif %}\\n    {{- system_message }}\\n    {{- \"<|eot|>\" }}\\n{%- endif %}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_content = messages[0][\\'content\\'] %}\\n        {%- set first_user_message = \"\" %}\\n        {%- if first_content is string %}\\n            {%- set first_user_message = first_content %}\\n        {%- else %}\\n            {%- for content in first_content %}\\n                {%- if content[\\'type\\'] == \\'image\\' %}\\n                    {%- set first_user_message = first_user_message + \\'<|image|>\\' %}\\n                {%- elif content[\\'type\\'] == \\'text\\' %}\\n                    {%- set first_user_message = first_user_message + content[\\'text\\'] %}\\n                {%- endif %}\\n            {%- endfor %}\\n        {%- endif %}\\n        {%- set first_user_message = first_user_message | trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|header_start|>user<|header_end|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n    {{- \\'<|header_start|>\\' + message[\\'role\\'] + \\'<|header_end|>\\\\n\\\\n\\' }}\\n        {%- if message[\\'content\\'] is string %}\\n            {{- message[\\'content\\'] }}\\n        {%- else %}\\n            {%- for content in message[\\'content\\'] %}\\n                {%- if content[\\'type\\'] == \\'image\\' %}\\n                    {{- \\'<|image|>\\' }}\\n                {%- elif content[\\'type\\'] == \\'text\\' %}\\n                    {{- content[\\'text\\'] }}\\n                {%- endif %}\\n            {%- endfor %}\\n        {%- endif %}\\n        {{- \"<|eot|>\" }}\\n    {%- elif \\'tool_calls\\' in message and message.tool_calls|length > 0 %}\\n      {{- \\'<|header_start|>assistant<|header_end|>\\\\n\\\\n\\' -}}\\n      {{- \\'<|python_start|>\\' }}\\n        {%- if message[\\'content\\'] is string %}\\n            {{- message[\\'content\\'] }}\\n        {%- else %}\\n            {%- for content in message[\\'content\\'] %}\\n                {%- if content[\\'type\\'] == \\'image\\' %}\\n                    {{- \\'<|image|>\\' }}\\n                {%- elif content[\\'type\\'] == \\'text\\' %}\\n                    {{- content[\\'text\\'] }}\\n                {%- endif %}\\n            {%- endfor %}\\n        {%- endif %}\\n      {{- \\'<|python_end|>\\' }}\\n        {%- for tool_call in message.tool_calls %}\\n          {{- \\'{\"name\": \"\\' + tool_call.function.name + \\'\", \\' }}\\n          {{- \\'\"parameters\": \\' }}\\n          {{- tool_call.function.arguments | tojson }}\\n          {{- \"}\" }}\\n        {%- endfor %}\\n      {{- \"<|eot|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|header_start|>ipython<|header_end|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|header_start|>assistant<|header_end|>\\\\n\\\\n\\' }}\\n{%- endif %}',\n",
              "   'stop': ['<|eot|>', '<|eom|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot|>'}},\n",
              " {'id': 'meta-llama/Llama-Guard-3-11B-Vision-Turbo',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1727242489,\n",
              "  'type': <ModelType.MODERATION: 'moderation'>,\n",
              "  'display_name': 'Meta Llama Guard 3 11B Vision Turbo',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Llama-Guard-3-11B-Vision',\n",
              "  'license': 'llama',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.18000000000000002,\n",
              "   'output': 0.18000000000000002,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- if messages|length % 2 == 0 -%}\\n    {%- set role = \\'Agent\\' -%}\\n{%-  else -%}\\n    {%-  set role = \\'User\\' -%}\\n{%-  endif -%}\\n{%-  if categories is not defined -%}\\n    {%-  \\n        set categories = ({\\n            \"S1\": \"Violent Crimes.\",\\n            \"S2\": \"Non-Violent Crimes.\",\\n            \"S3\": \"Sex Crimes.\",\\n            \"S4\": \"Child Exploitation.\",\\n            \"S5\": \"Defamation.\",\\n            \"S6\": \"Specialized Advice.\",\\n            \"S7\": \"Privacy.\",\\n            \"S8\": \"Intellectual Property.\",\\n            \"S9\": \"Indiscriminate Weapons.\",\\n            \"S10\": \"Hate.\",\\n            \"S11\": \"Self-Harm.\",\\n            \"S12\": \"Sexual Content.\",\\n            \"S13\": \"Elections.\",\\n        })\\n    -%}\\n{%-  endif -%}\\n\\n{{- \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\\\n\\\\n\" -}}\\n{%- set ns = namespace(contains_image=false) -%}\\n{%-  for message in messages -%}\\n    {%- for content in message[\\'content\\'] | selectattr(\\'type\\', \\'equalto\\', \\'image\\') -%}\\n        {%- set ns.contains_image = true -%}\\n    {%- endfor -%}\\n{%- endfor -%}\\n{%- if ns.contains_image -%}\\n{{- \"<|image|> \"-}}\\n{%- endif -%}\\n{{- \"Task: Check if there is unsafe content in \\'\" + role + \"\\' messages in conversations according our safety policy with the below categories.\\\\n\\\\n\" -}}\\n{{- \"<BEGIN UNSAFE CONTENT CATEGORIES>\\\\n\"-}}\\n\\n{%-  for key in categories -%}\\n    {%-  if key not in excluded_category_keys -%}\\n        {{-key + \": \" + categories[key] + \"\\\\n\" -}}\\n    {%-  endif -%}\\n{%-  endfor -%}\\n\\n{{- \"<END UNSAFE CONTENT CATEGORIES>\\\\n\\\\n\"-}}\\n{{- \"<BEGIN CONVERSATION>\\\\n\\\\n\"-}}\\n{%-  for message in messages -%}\\n    {%-  if (message[\\'role\\'] == \\'user\\') != (loop.index0 % 2 == 0) -%}\\n        {{ raise_exception(\\'Conversation roles must alternate user/assistant/user/assistant/...\\')-}}\\n    {%-  endif -%}\\n    {%-  set content = message[\\'content\\'] -%}\\n    {%-  if message[\\'role\\'] == \\'user\\' -%}\\n        {%-  set role = \\'User\\' -%}\\n    {%-  elif message[\\'role\\'] == \\'assistant\\' -%}\\n        {%-  set role = \\'Agent\\' -%}\\n    {%-  endif -%}\\n    {%-  for content in message[\\'content\\'] | selectattr(\\'type\\', \\'equalto\\', \\'text\\') -%}\\n{{- role + \\': \\' + content[\\'text\\'] | trim + \\'\\\\n\\\\n\\'-}}\\n    {%-  endfor -%}\\n{%-  endfor -%}\\n{{- \"<END CONVERSATION>\\\\n\\\\n\"-}}\\n{{- \"Provide your safety assessment for ONLY THE LAST \" + role + \" message in the above conversation:\\\\n\"-}}\\n{{- \" - First line must read \\'safe\\' or \\'unsafe\\'.\\\\n\"-}}\\n{{- \" - If unsafe, a second line must include a comma-separated list of violated categories. <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"-}}',\n",
              "   'stop': ['<|eot_id|>', '<|eom_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'meta-llama/Llama-Guard-4-12B',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1746038486,\n",
              "  'type': <ModelType.MODERATION: 'moderation'>,\n",
              "  'display_name': 'Llama Guard 4 12B',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Llama-Guard-4-12B',\n",
              "  'license': 'other llama4',\n",
              "  'context_length': 1048576,\n",
              "  'pricing': {'input': 0.2,\n",
              "   'output': 0.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- if messages | length % 2 == 0 -%}\\n    {%- set role = \\'Agent\\' -%}\\n{%- else -%}\\n    {%- set role = \\'User\\' -%}\\n{%- endif -%}\\n\\n{%- if categories is not defined -%}\\n    {%- set ns = namespace(contains_image=false) -%}\\n\\n    {%- for message in messages -%}\\n        {%- for content in message[\\'content\\'] | selectattr(\\'type\\', \\'equalto\\', \\'image\\') -%}\\n            {%- set ns.contains_image = true -%}\\n        {%- endfor -%}\\n    {%- endfor -%}\\n\\n    {%- if ns.contains_image -%}\\n        {%- set categories = {\\n            \"S1\": \"Violent Crimes.\",\\n            \"S2\": \"Non-Violent Crimes.\",\\n            \"S3\": \"Sex Crimes.\",\\n            \"S4\": \"Child Exploitation.\",\\n            \"S5\": \"Defamation.\",\\n            \"S6\": \"Specialized Advice.\",\\n            \"S7\": \"Privacy.\",\\n            \"S8\": \"Intellectual Property.\",\\n            \"S9\": \"Indiscriminate Weapons.\",\\n            \"S10\": \"Hate.\",\\n            \"S11\": \"Self-Harm.\",\\n            \"S12\": \"Sexual Content.\",\\n            \"S13\": \"Elections.\",\\n        } -%}\\n    {%- else -%}\\n        {%- set categories = {\\n            \"S1\": \"Violent Crimes.\",\\n            \"S2\": \"Non-Violent Crimes.\",\\n            \"S3\": \"Sex Crimes.\",\\n            \"S4\": \"Child Exploitation.\",\\n            \"S5\": \"Defamation.\",\\n            \"S6\": \"Specialized Advice.\",\\n            \"S7\": \"Privacy.\",\\n            \"S8\": \"Intellectual Property.\",\\n            \"S9\": \"Indiscriminate Weapons.\",\\n            \"S10\": \"Hate.\",\\n            \"S11\": \"Self-Harm.\",\\n            \"S12\": \"Sexual Content.\",\\n            \"S13\": \"Elections.\",\\n            \"S14\": \"Code Interpreter Abuse.\",\\n        } -%}\\n    {%- endif -%}\\n{%- endif -%}\\n\\n{{ \"<|begin_of_text|><|header_start|>user<|header_end|>\\\\n\" }}\\n{{ \"Task: Check if there is unsafe content in \\'\" + role + \"\\' messages in conversations according to our safety policy with the below categories.\\\\n\" }}\\n{{ \"<BEGIN UNSAFE CONTENT CATEGORIES>\\\\n\" }}\\n\\n{%- for key in categories -%}\\n    {%- if key not in excluded_category_keys -%}\\n        {{ key + \": \" + categories[key] + \"\\\\n\" }}\\n    {%- endif -%}\\n{%- endfor -%}\\n\\n{{ \"<END UNSAFE CONTENT CATEGORIES>\\\\n\" }}\\n{{ \"<BEGIN CONVERSATION>\\\\n\" }}\\n\\n{%- for message in messages -%}\\n    {%- if (message[\\'role\\'] == \\'user\\') != (loop.index0 % 2 == 0) -%}\\n        {{ raise_exception(\\'Conversation roles must alternate user/assistant/user/assistant/...\\') }}\\n    {%- endif -%}\\n\\n    {%- set content = message[\\'content\\'] -%}\\n\\n    {%- if message[\\'role\\'] == \\'user\\' -%}\\n        {%- set role = \\'User\\' -%}\\n    {%- elif message[\\'role\\'] == \\'assistant\\' -%}\\n        {%- set role = \\'Agent\\' -%}\\n    {%- endif -%}\\n\\n    {#— #1 Accumulate all images for this message —#}\\n    {%- set ns = namespace(img_tokens=\\'\\') -%}\\n    {%- for img in message.content | selectattr(\\'type\\', \\'equalto\\', \\'image\\') -%}\\n        {%- set ns.img_tokens = ns.img_tokens + \\'<|image|>\\' -%}\\n    {%- endfor -%}\\n\\n    {#— #2 Then emit all text —#}\\n    {%- for txt in message.content | selectattr(\\'type\\',\\'equalto\\',\\'text\\') -%}\\n        {{ role + \\': \\' }}{{ ns.img_tokens }}{{ txt.text | trim }}\\\\n\\\\n\\n\\n        {#— clear the buffer so only first text prints images —#}\\n        {%- if loop.first -%}\\n            {%- set ns.img_tokens = \\'\\' -%}\\n        {%- endif -%}\\n    {%- endfor -%}\\n{%- endfor -%}\\n\\n{{ \"<END CONVERSATION>\\\\n\" }}\\n{{ \"Provide your safety assessment for ONLY THE LAST \" + role + \" message in the above conversation:\" }}\\n{{ \" - First line must read \\'safe\\' or \\'unsafe\\'.\" }}\\n{{ \" - If unsafe, a second line must include a comma-separated list of violated categories. <|eot|><|header_start|>assistant<|header_end|>\" }}',\n",
              "   'stop': ['<|eot|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot|>'}},\n",
              " {'id': 'meta-llama/Llama-Vision-Free',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1727236346,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama Vision Free',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct',\n",
              "  'license': 'llama',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{% for message in messages %}\\n{% if loop.index0 == 0 %}{{ bos_token }}{% endif %}\\n{{ \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\' }}\\n{% if message[\\'content\\'] is string %}\\n{{ message[\\'content\\'] }}\\n{% else %}\\n{% for content in message[\\'content\\'] | sort(attribute=\"type\") %}\\n{% if content[\\'type\\'] == \\'image\\' %}\\n{{ \\'<|image|>\\' }}\\n{% elif content[\\'type\\'] == \\'text\\' %}\\n{{ content[\\'text\\'] }}\\n{% endif %}\\n{% endfor %}\\n{% endif %}\\n{{ \\'<|eot_id|>\\' }}\\n{% endfor %}\\n{% if add_generation_prompt %}\\n{{ \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{% endif %}',\n",
              "   'stop': ['<|eot_id|>', '<|eom_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'meta-llama/LlamaGuard-2-8b',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1713429380,\n",
              "  'type': <ModelType.MODERATION: 'moderation'>,\n",
              "  'display_name': 'Meta Llama Guard 2 8B',\n",
              "  'organization': 'Meta',\n",
              "  'license': 'Llama-3 (Other)',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.2,\n",
              "   'output': 0.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% if messages.length % 2 == 0 %}{% set final_role = 'Agent' %}{% else %}{% set final_role = 'User' %}{% endif %}[INST] Task: Check if there is unsafe content in '{{ final_role }}' messages in conversations according our safety policy with the below categories.\\n\\n<BEGIN UNSAFE CONTENT CATEGORIES>\\nS1: Violent Crimes.\\nS2: Non-Violent Crimes.\\nS3: Sex Crimes.\\nS4: Child Exploitation.\\nS5: Specialized Advice.\\nS6: Privacy.\\nS7: Intellectual Property.\\nS8: Indiscriminate Weapons.\\nS9: Hate.\\nS10: Self-Harm.\\nS11: Sexual Content.\\n<END UNSAFE CONTENT CATEGORIES>\\n\\n<BEGIN CONVERSATION>\\n\\n{% for message in messages %}{% if message['role'] == 'user' and loop.index0 % 2 == 0 %}User: {{ message['content'].trim() }}{% elif message['role'] == 'assistant' and loop.index0 % 2 != 0 %}Agent: {{ message['content'].trim() }}{% else %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.last %}{% set role = message['role'] %}{% endif %}{{ '\\n\\n' }}{% endfor %}<END CONVERSATION>\\n\\nProvide your safety assessment for ONLY THE LAST {{ role }} message in the above conversation:\\n - First line must read 'safe' or 'unsafe'.\\n - If unsafe, a second line must include a comma-separated list of violated categories. [/INST]\",\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'meta-llama/Meta-Llama-3-70B-Instruct-Turbo',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 0,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama 3 70B Instruct Turbo',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct',\n",
              "  'license': 'Llama-3 (Other)',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.88,\n",
              "   'output': 0.88,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\",\n",
              "   'stop': ['<|eot_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|end_of_text|>'}},\n",
              " {'id': 'meta-llama/Meta-Llama-3-8B-Instruct-Lite',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 0,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama 3 8B Instruct Lite',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct',\n",
              "  'license': 'Llama-3 (Other)',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.1,\n",
              "   'output': 0.1,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\",\n",
              "   'stop': ['<|eot_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|end_of_text|>',\n",
              "   'max_output_length': 8192}},\n",
              " {'id': 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1721698359,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama 3.1 405B Instruct Turbo',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct',\n",
              "  'license': 'llama',\n",
              "  'context_length': 130815,\n",
              "  'pricing': {'input': 3.5,\n",
              "   'output': 3.5,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': ['<|eot_id|>', '<|eom_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1721603683,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama 3.1 70B Instruct Turbo',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct',\n",
              "  'license': 'Llama-3.1 (Other)',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.88,\n",
              "   'output': 0.88,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \"Tools: \" + builtin_tools | reject(\\'equalto\\', \\'code_interpreter\\') | join(\", \") + \"\\\\n\\\\n\"}}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + \\'=\"\\' + arg_val + \\'\"\\' }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \")\" }}\\n        {%- else  %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n            {{- \\'\"parameters\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \"}\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we\\'re in ipython mode #}\\n            {{- \"<|eom_id|>\" }}\\n        {%- else %}\\n            {{- \"<|eot_id|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|eot_id|>', '<|eom_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1741298134,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Meta Llama 3.1 8B Instruct Turbo',\n",
              "  'organization': 'Meta',\n",
              "  'link': 'https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct',\n",
              "  'license': 'Llama-3.1 (Other)',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 0.18000000000000002,\n",
              "   'output': 0.18000000000000002,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \"Tools: \" + builtin_tools | reject(\\'equalto\\', \\'code_interpreter\\') | join(\", \") + \"\\\\n\\\\n\"}}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + \\'=\"\\' + arg_val + \\'\"\\' }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \")\" }}\\n        {%- else  %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n            {{- \\'\"parameters\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \"}\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we\\'re in ipython mode #}\\n            {{- \"<|eom_id|>\" }}\\n        {%- else %}\\n            {{- \"<|eot_id|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|eot_id|>', '<|eom_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'meta-llama/Meta-Llama-Guard-3-8B',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1713429380,\n",
              "  'type': <ModelType.MODERATION: 'moderation'>,\n",
              "  'display_name': 'Meta Llama Guard 3 8B',\n",
              "  'organization': 'Meta',\n",
              "  'license': 'llama',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.2,\n",
              "   'output': 0.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% if messages.length % 2 == 0 %}{% set final_role = 'Agent' %}{% else %}{% set final_role = 'User' %}{% endif %}<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nTask: Check if there is unsafe content in '{{ final_role }}' messages in conversations according our safety policy with the below categories.\\n\\n<BEGIN UNSAFE CONTENT CATEGORIES>\\nS1: Violent Crimes.\\nS2: Non-Violent Crimes.\\nS3: Sex Crimes.\\nS4: Child Exploitation.\\nS5: Defamation.\\nS6: Specialized Advice.\\nS7: Privacy.\\nS8: Intellectual Property.\\nS9: Indiscriminate Weapons.\\nS10: Hate.\\nS11: Self-Harm.\\nS12: Sexual Content.\\nS13: Elections.\\nS14: Code Interpreter Abuse.\\n<END UNSAFE CONTENT CATEGORIES>\\n\\n<BEGIN CONVERSATION>\\n\\n{% for message in messages %}{% if message['role'] == 'user' and loop.index0 % 2 == 0 %}User: {{ message['content'].trim() }}{% elif message['role'] == 'assistant' and loop.index0 % 2 != 0 %}Agent: {{ message['content'].trim() }}{% endif %}{% if loop.last %}{% set role = message['role'] %}{% endif %}{{ '\\n\\n' }}{% endfor %}<END CONVERSATION>\\n\\nProvide your safety assessment for {{ role }} in the above conversation:\\n - First line must read 'safe' or 'unsafe'.\\n - If unsafe, a second line must include a comma-separated list of violated categories.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'mistralai/Mistral-7B-Instruct-v0.1',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1695860851,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Mistral (7B) Instruct',\n",
              "  'organization': 'mistralai',\n",
              "  'link': 'https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.1',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.2,\n",
              "   'output': 0.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\\\n' + system_message + '\\\\n<</SYS>>\\\\n\\\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' or message['role'] == 'tool' %}{{ bos_token + '[INST] ' + content + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\\\\n' + content + '\\\\n<</SYS>>\\\\n\\\\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content + ' ' + eos_token }}{% endif %}{% endfor %}\",\n",
              "   'stop': ['</s>'],\n",
              "   'bos_token': '<s>',\n",
              "   'eos_token': '</s>'}},\n",
              " {'id': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1702325373,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Mistral (7B) Instruct v0.2',\n",
              "  'organization': 'mistralai',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.2,\n",
              "   'output': 0.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\\\n' + system_message + '\\\\n<</SYS>>\\\\n\\\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' or message['role'] == 'tool' %}{{ bos_token + '[INST] ' + content + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\\\\n' + content + '\\\\n<</SYS>>\\\\n\\\\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content + ' ' + eos_token }}{% endif %}{% endfor %}\",\n",
              "   'stop': ['[/INST]', '</s>'],\n",
              "   'bos_token': '<s>',\n",
              "   'eos_token': '</s>'}},\n",
              " {'id': 'mistralai/Mistral-7B-Instruct-v0.3',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1716406261,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Mistral (7B) Instruct v0.3',\n",
              "  'organization': 'mistralai',\n",
              "  'link': 'https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.3',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.2,\n",
              "   'output': 0.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\\\n' + system_message + '\\\\n<</SYS>>\\\\n\\\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' or message['role'] == 'tool' %}{{ bos_token + '[INST] ' + content + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\\\\n' + content + '\\\\n<</SYS>>\\\\n\\\\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content + ' ' + eos_token }}{% endif %}{% endfor %}\",\n",
              "   'stop': ['</s>'],\n",
              "   'bos_token': '<s>',\n",
              "   'eos_token': '</s>'}},\n",
              " {'id': 'mistralai/Mistral-Small-24B-Instruct-2501',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1738246136,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Mistral Small (24B) Instruct 25.01',\n",
              "  'organization': 'mistralai',\n",
              "  'link': 'https://huggingface.co/mistralai/Mistral-Small-Instruct-2501',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.8,\n",
              "   'output': 0.8,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- if messages[0][\"role\"] == \"system\" %}{%- set system_message = messages[0][\"content\"] %}{%- set loop_messages = messages[1:] %}{%- else %}{%- set today = strftime_now(\"%Y-%m-%d\") %}{%- set system_message = \"You are Mistral Small 3, a Large Language Model (LLM) created by Mistral AI, a French startup headquartered in Paris.\\\\nYour knowledge base was last updated on 2023-10-01. The current date is \" + today + \".\\\\n\\\\nWhen you\\'re not sure about some information, you say that you don\\'t have the information and don\\'t make up anything.\\\\nIf the user\\'s question is not clear, ambiguous, or does not provide enough context for you to accurately answer the question, you do not try to answer it right away and you rather ask the user to clarify their request (e.g. \\\\\"What are some good restaurants around me?\\\\\" => \\\\\"Where are you?\\\\\" or \\\\\"When is the next flight to Tokyo\\\\\" => \\\\\"Where do you travel from?\\\\\")\" %}{%- set loop_messages = messages %}{%- endif %}{%- if not tools is defined %}{%- set tools = none %}{%- elif tools is not none %}{%- set parallel_tool_prompt = \"You are a helpful assistant that can call tools. If you call one or more tools, format them in a single JSON array or objects, where each object is a tool call, not as separate objects outside of an array or multiple arrays. Use the format [{\\\\\"name\\\\\": tool call name, \\\\\"arguments\\\\\": tool call arguments}, additional tool calls] if you call more than one tool. If you call tools, do not attempt to interpret them or otherwise provide a response until you receive a tool call result that you can interpret for the user.\" %}{%- if system_message is defined %}{%- set system_message = parallel_tool_prompt + \"\\\\n\\\\n\" + system_message %}{%- else %}{%- set system_message = parallel_tool_prompt %}{%- endif %}\\n{%- endif %}{%- set user_messages = loop_messages | selectattr(\"role\", \"equalto\", \"user\") | list %}{%- for message in loop_messages | rejectattr(\"role\", \"equalto\", \"tool\") | rejectattr(\"role\", \"equalto\", \"tool_results\") | selectattr(\"tool_calls\", \"undefined\") %}{%- if (message[\"role\"] == \"user\") != (loop.index0 % 2 == 0) %}{{- raise_exception(\"After the optional system message, conversation roles must alternate user/assistant/user/assistant/...\") }}{%- endif %}{%- endfor %}{{- bos_token }}{%- for message in loop_messages %}{%- if message[\"role\"] == \"user\" %}{%- if tools is not none and (message == user_messages[user_messages.length-1]) %}{{- \"[AVAILABLE_TOOLS] [\" }}{%- for tool in tools %}{%- set tool = tool.function %}{{- \\'{\"type\": \"function\", \"function\": {\\' }}{%- for key, val in tool.items() if key != \"return\" %}{%- if val is string %}{{- \\'\"\\' + key + \\'\": \"\\' + val + \\'\"\\' }}{%- else %}{{- \\'\"\\' + key + \\'\": \\' + val|tojson }}{%- endif %}{%- if not loop.last %}{{- \", \" }}{%- endif %}{%- endfor %}{{- \"}}\" }}{%- if not loop.last %}{{- \", \" }}{%- else %}{{- \"]\" }}{%- endif %}{%- endfor %}{{- \"[/AVAILABLE_TOOLS]\" }}{%- endif %}{%- if loop.last and system_message is defined %}{{- \"[SYSTEM_PROMPT]\" + system_message + \"[/SYSTEM_PROMPT][INST]\" + message[\"content\"] + \"[/INST]\" }}{%- else %}{{- \"[INST]\" + message[\"content\"] + \"[/INST]\" }}{%- endif %}{%- elif message[\"role\"] == \"tool_calls\" or message.tool_calls is defined %}{%- if message.tool_calls is defined %}{%- set tool_calls = message.tool_calls %}{%- else %}{%- set tool_calls = message.content %}{%- endif %}{{- \"[TOOL_CALLS] [\" }}{%- for tool_call in tool_calls %}{%- set out = tool_call.function|tojson %}{{- out }}{%- if not tool_call.id is defined or tool_call.id|length < 9 %}{{- raise_exception(\"Tool call IDs should be alphanumeric strings with length >= 9! (1)\" + tool_call.id) }}{%- endif %}{{- \\', \"id\": \"\\' + tool_call.id + \\'\"}\\' }}{%- if not loop.last %}{{- \", \" }}{%- else %}{{- \"]\" + eos_token }}{%- endif %}{%- endfor %}{%- elif message[\"role\"] == \"assistant\" %}{{- \" \" + message[\"content\"] + eos_token }}{%- elif message[\"role\"] == \"tool_results\" or message[\"role\"] == \"tool\" %}{%- if message.content is defined and message.content.content is defined %}{%- set content = message.content.content %}{%- else %}{%- set content = message.content %}{%- endif %}{{- \\'[TOOL_RESULTS] {\"content\": \\' + content|string + \", \" }}{%- if not message.tool_call_id is defined or message.tool_call_id|length < 9 %}{{- raise_exception(\"Tool call IDs should be alphanumeric strings with length >= 9! (2)\" + message.tool_call_id) }}{%- endif %}{{- \\'\"call_id\": \"\\' + message.tool_call_id + \\'\"}[/TOOL_RESULTS]\\' }}{%- else %}{{- raise_exception(\"Only user and assistant roles are supported, with the exception of an initial optional system message!\") }}{%- endif %}\\n{%- endfor %}',\n",
              "   'stop': ['[/INST]', '</s>'],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1702342468,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Mixtral-8x7B Instruct v0.1',\n",
              "  'organization': 'mistralai',\n",
              "  'link': 'https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.6,\n",
              "   'output': 0.6,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\\\n' + system_message + '\\\\n<</SYS>>\\\\n\\\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' or message['role'] == 'tool' %}{{ bos_token + '[INST] ' + content + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\\\\n' + content + '\\\\n<</SYS>>\\\\n\\\\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content + ' ' + eos_token }}{% endif %}{% endfor %}\",\n",
              "   'stop': ['[/INST]', '</s>'],\n",
              "   'bos_token': '<s>',\n",
              "   'eos_token': '</s>'}},\n",
              " {'id': 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1705292440,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Nous Hermes 2 Mixtral 8X7B Dpo',\n",
              "  'organization': 'Nousresearch',\n",
              "  'link': 'https://huggingface.co/api/models/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.6,\n",
              "   'output': 0.6,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{{bos_token}}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\",\n",
              "   'stop': ['<|im_end|>'],\n",
              "   'bos_token': '<s>',\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'nvidia/Llama-3.1-Nemotron-70B-Instruct-HF',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1731110984,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Llama 3.1 Nemotron 70B Instruct HF',\n",
              "  'organization': 'nvidia',\n",
              "  'link': 'https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF',\n",
              "  'license': 'llama3.1',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.88,\n",
              "   'output': 0.88,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \"Tools: \" + builtin_tools | reject(\\'equalto\\', \\'code_interpreter\\') | join(\", \") + \"\\\\n\\\\n\"}}\\n{%- endif %}\\n\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + \\'=\"\\' + arg_val + \\'\"\\' }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \")\" }}\\n        {%- else  %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n            {{- \\'\"parameters\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \"}\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we\\'re in ipython mode #}\\n            {{- \"<|eom_id|>\" }}\\n        {%- else %}\\n            {{- \"<|eot_id|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|eot_id|>', '<|eom_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'perplexity-ai/r1-1776',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1746135809,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'R1 1776',\n",
              "  'organization': 'Perplexity AI',\n",
              "  'link': 'https://huggingface.co/api/models/perplexity-ai/r1-1776',\n",
              "  'license': 'mit',\n",
              "  'context_length': 163840,\n",
              "  'pricing': {'input': 3.0,\n",
              "   'output': 7.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': ['<｜end▁of▁sentence｜>'],\n",
              "   'bos_token': '<｜begin▁of▁sentence｜>',\n",
              "   'eos_token': '<｜end▁of▁sentence｜>',\n",
              "   'max_output_length': 32768}},\n",
              " {'id': 'Qwen/Qwen2-72B-Instruct',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1744167438,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Qwen 2 Instruct (72B)',\n",
              "  'organization': 'Qwen',\n",
              "  'link': 'https://huggingface.co/Qwen/Qwen2-72B-Instruct',\n",
              "  'license': 'tongyi-qianwen',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.9,\n",
              "   'output': 0.9,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\",\n",
              "   'stop': ['<|im_start|>', '<|im_end|>'],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'Qwen/Qwen2-VL-72B-Instruct',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1736448718,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Qwen2-VL (72B) Instruct',\n",
              "  'organization': 'Qwen',\n",
              "  'link': 'https://huggingface.co/Qwen/Qwen2-VL-72B-Instruct',\n",
              "  'license': 'tongyi-qianwen',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 1.2,\n",
              "   'output': 1.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\",\n",
              "   'stop': ['<|im_end|>', '<|endoftext|>'],\n",
              "   'bos_token': None,\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'Qwen/Qwen2.5-72B-Instruct-Turbo',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1728633510,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Qwen2.5 72B Instruct Turbo',\n",
              "  'organization': 'Qwen',\n",
              "  'link': 'https://huggingface.co/Qwen/Qwen2.5-72B-Instruct',\n",
              "  'license': 'Qwen',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 1.2,\n",
              "   'output': 1.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|im_end|>'],\n",
              "   'bos_token': '<|endoftext|>',\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'Qwen/Qwen2.5-7B-Instruct-Turbo',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1728671048,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Qwen2.5 7B Instruct Turbo',\n",
              "  'organization': 'Qwen',\n",
              "  'link': 'https://huggingface.co/Qwen/Qwen2.5-7B-Instruct',\n",
              "  'license': 'Qwen',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.3,\n",
              "   'output': 0.3,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|im_end|>'],\n",
              "   'bos_token': '<|endoftext|>',\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'Qwen/Qwen2.5-Coder-32B-Instruct',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1731556615,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Qwen 2.5 Coder 32B Instruct',\n",
              "  'organization': 'Qwen',\n",
              "  'link': 'https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct',\n",
              "  'license': 'Qwen',\n",
              "  'context_length': 16384,\n",
              "  'pricing': {'input': 0.8,\n",
              "   'output': 0.8,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|im_end|>'],\n",
              "   'bos_token': '<|endoftext|>',\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'Qwen/Qwen2.5-VL-72B-Instruct',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1742408085,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Qwen2.5-VL (72B) Instruct',\n",
              "  'organization': 'Qwen',\n",
              "  'link': 'https://huggingface.co/api/models/Qwen/Qwen2.5-VL-72B-Instruct',\n",
              "  'license': 'tongyi-qianwen',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 1.95,\n",
              "   'output': 8.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\",\n",
              "   'stop': ['<|im_end|>', '<|endoftext|>'],\n",
              "   'bos_token': None,\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'Qwen/Qwen3-235B-A22B-fp8-tput',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1747854468,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Qwen3 235B A22B FP8 Throughput',\n",
              "  'organization': 'Qwen',\n",
              "  'link': 'https://huggingface.co/api/models/Qwen/Qwen3-235B-A22B',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 40960,\n",
              "  'pricing': {'input': 0.2,\n",
              "   'output': 0.6,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': ['<|im_end|>'],\n",
              "   'bos_token': '<|endoftext|>',\n",
              "   'eos_token': '<|im_end|>'}},\n",
              " {'id': 'Qwen/QwQ-32B',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1741207789,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Qwen QwQ-32B',\n",
              "  'organization': 'Qwen',\n",
              "  'link': 'https://huggingface.co/Qwen/QwQ-32B',\n",
              "  'license': 'Qwen',\n",
              "  'context_length': 131072,\n",
              "  'pricing': {'input': 1.2,\n",
              "   'output': 1.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are a helpful and harmless assistant. You are Qwen developed by Alibaba. You should think step-by-step.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n',\n",
              "   'stop': ['<|im_end|>', '<|endoftext|>'],\n",
              "   'bos_token': None,\n",
              "   'eos_token': '<|im_end|>',\n",
              "   'max_output_length': 32768}},\n",
              " {'id': 'Salesforce/Llama-Rank-V1',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1723745254,\n",
              "  'type': <ModelType.RERANK: 'rerank'>,\n",
              "  'display_name': 'Salesforce Llama Rank V1 (8B)',\n",
              "  'organization': 'salesforce',\n",
              "  'license': 'llama3',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.1,\n",
              "   'output': 0.1,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\nAfter carefully reading the query, document, and guidelines, I have determined that the relevance score is: ' }}{% endif %}\",\n",
              "   'stop': ['<|eot_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'scb10x/scb10x-llama3-1-typhoon2-70b-instruct',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1743036812,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Typhoon 2 70B Instruct',\n",
              "  'organization': 'SCB10X',\n",
              "  'link': 'https://huggingface.co/api/models/scb10x/llama3.1-typhoon2-70b-instruct',\n",
              "  'license': 'llama3.1',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.88,\n",
              "   'output': 0.88,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{{- system_message }}\\n{%- if tools is not none %}\\n    {{- \"\\\\n\" }}\\n    {{- \"You are given a question and a set of possible functions. Based on the question, you will need to make one or more function/tool calls to achieve the purpose.\" }}\\n    {{- \"If none of the function can be used, point it out. If the given question lacks the parameters required by the function, also point it out.\" }}\\n    {{- \"You should only return the function call in tools call sections.\" }}\\n    {{- \"If you decide to invoke any of the function(s), you MUST put it in the format of [Function(arguments1={{params_name1: params_value1,params_name2: params_value2, ...}},  name1=function_name1), Function(arguments2={{params}},  name2=function_name2) , ...]\"}}\\n    {{- \"You SHOULD NOT include any other text in the response.\\\\nHere is a list of functions in JSON format that you can invoke.\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- \"<|eot_id|>\" }}\\n\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'tool\\') %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {{- \"<|start_header_id|>tool<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}',\n",
              "   'stop': ['<|eot_id|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|eot_id|>'}},\n",
              " {'id': 'scb10x/scb10x-typhoon-2-1-gemma3-12b',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1749574497,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Typhoon 2.1 12B',\n",
              "  'link': 'https://huggingface.co/api/models/togethercomputer/typhoon2.1-gemma3-12b',\n",
              "  'license': 'gemma',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.2,\n",
              "   'output': 0.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': '{#- Begin-of-sequence token to start the model prompt -#}\\n{{ bos_token }}\\n{#- Extracts the system message. Gemma does not support system messages so it will be prepended to first user message. -#}\\n{%- if messages[0][\\'role\\'] == \\'system\\' -%}\\n    {%- if messages[0][\\'content\\'] is string -%}\\n        {%- set first_user_prefix = messages[0][\\'content\\'] -%}\\n    {%- else -%}\\n        {%- set first_user_prefix = messages[0][\\'content\\'][0][\\'text\\'] -%}\\n    {%- endif -%}\\n    {%- set loop_messages = messages[1:] -%}\\n{%- else -%}\\n    {%- set first_user_prefix = \"You are a helpful assistant named Typhoon created by SCB 10X to be helpful, harmless, and honest.\" -%}\\n    {%- set loop_messages = messages -%}\\n{%- endif -%}\\n{%- if enable_thinking is defined and enable_thinking is true %}\\n    {%- set first_user_prefix = first_user_prefix + \" First, think through the reasoning internally, then present the reasoning within <think>...</think>. After thinking, clearly state a response that addresses the user\\'s request and aligns with their preferences, not just providing a direct answer.\" -%}\\n{%- endif %}\\n{%- set first_user_prefix = first_user_prefix + \\'\\\\n\\\\n\\' -%}\\n{#- Set tools to none if not defined for this ChatCompletion request (helps avoid errors later) -#}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- If given only system message -#}\\n{%- if loop_messages|length == 0 -%}\\n    {{ \\'<start_of_turn>user\\\\n\\' -}}\\n    {{ first_user_prefix }}\\n    {#- Append system message with tool information if using tools in message request. -#}\\n    {%- if tools is not none -%}\\n        {{- \"Tools (functions) are available. If you decide to invoke one or more of the tools, you must respond with a python list of the function calls.\\\\n\" -}}\\n        {{- \"Example Format: [func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)] \\\\n\" -}}\\n        {{- \"Do not use variables. DO NOT USE MARKDOWN SYNTAX. You SHOULD NOT include any other text in the response if you call a function. If none of the functions can be used, point it out. If you lack the parameters required by the function, also point it out.\\\\n\" -}}\\n        {{- \"Here is a list of functions in JSON format that you can invoke.\\\\n\" -}}\\n        {{- tools | tojson(indent=4) -}}\\n        {{- \"\\\\n\\\\n\" -}}\\n    {%- endif -%}\\n{%- endif %}\\n\\n{#- Main loop over all messages in the conversation history -#}\\n{%- for message in loop_messages -%}\\n    {#- Normalize roles for model prompt formatting -#}\\n    {%- if (message[\\'role\\'] == \\'assistant\\') -%}\\n        {%- set role = \"model\" -%}\\n    {%- elif (message[\\'role\\'] == \\'tool\\') -%}\\n        {%- set role = \"user\" -%}\\n    {%- else -%}\\n        {%- set role = message[\\'role\\'] -%}\\n    {%- endif -%}\\n    {#- Mark the start of a message block with the appropriate role -#}\\n    {{ \\'<start_of_turn>\\' + role + \\'\\\\n\\' -}}\\n\\n    {#- Insert system message content (if present) at the beginning of the first message. -#}\\n    {%- if loop.first -%}\\n        {{ first_user_prefix }}\\n        {#- Append system message with tool information if using tools in message request. -#}\\n        {%- if tools is not none -%}\\n            {{- \"Tools (functions) are available. If you decide to invoke one or more of the tools, you must respond with a python list of the function calls.\\\\n\" -}}\\n            {{- \"Example Format: [func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)] \\\\n\" -}}\\n            {{- \"Do not use variables. DO NOT USE MARKDOWN SYNTAX. You SHOULD NOT include any other text in the response if you call a function. If none of the functions can be used, point it out. If you lack the parameters required by the function, also point it out.\\\\n\" -}}\\n            {{- \"Here is a list of functions in JSON format that you can invoke.\\\\n\" -}}\\n            {{- tools | tojson(indent=4) -}}\\n            {{- \"\\\\n\\\\n\" -}}\\n        {%- endif -%}\\n    {%- endif -%}\\n\\n    {#- Format model tool calls (turns where model indicates they want to call a tool) -#}\\n    {%- if \\'tool_calls\\' in message -%}\\n        {#- Opening bracket for tool call list. -#}\\n        {{- \\'[\\' -}}\\n        {#- For each tool call -#}\\n        {%- for tool_call in message.tool_calls -%}\\n            {#- Function name & opening parenthesis. -#}\\n            {%- if tool_call.function is defined -%}\\n                {%- set tool_call = tool_call.function -%}\\n            {%- endif -%}\\n            {{- tool_call.name + \\'(\\' -}}\\n\\n            {#-- Handle arguments as list (positional) or dict (named) --#}\\n            {#-- Named arguments (dict) --#}\\n            {%- if tool_call.arguments is iterable and tool_call.arguments is mapping -%}\\n                {%- set first = true -%}\\n                {%- for key, val in tool_call.arguments.items() -%}\\n                    {%- if not first %}, {% endif -%}\\n                    {{ key }}={{ val | tojson }}\\n                    {%- set first = false -%}\\n                {%- endfor -%}\\n            {#-- Positional arguments (list) --#}\\n            {%- elif tool_call.arguments is iterable -%}\\n                {{- tool_call.arguments | map(\\'tojson\\') | join(\\', \\') -}}\\n            {#-- Fallback: single positional value --#}\\n            {%- else -%}\\n                {{- tool_call.arguments | tojson -}}\\n            {#-- Closing parenthesis. --#}\\n            {%- endif -%}\\n                {{- \\')\\' -}}\\n            {#-- If more than one tool call, place comma and move to formatting next tool call --#}\\n            {%- if not loop.last -%}, {% endif -%}\\n        {%- endfor -%}\\n        {#- Closing bracket for tool call list. -#}\\n        {{- \\']\\' -}}\\n    {%- endif -%}\\n    \\n    {#- Tool response start tag (for messages from a tool) -#}\\n    {%- if (message[\\'role\\'] == \\'tool\\') -%}\\n        {{ \\'<tool_response>\\\\n\\' -}}\\n    {%- endif -%}\\n\\n    {#- Render the message content: handle plain string or multimodal content like image/text -#}\\n    {%- if message[\\'content\\'] is string -%}\\n        {%- set content = message[\\'content\\'] -%}\\n        {%- if \\'</think>\\' in content -%}\\n            {%- set content = content.split(\\'</think>\\')[-1] -%}\\n        {%- endif -%}\\n        {{ content | trim }}\\n    {%- elif message[\\'content\\'] is iterable -%}\\n        {%- for item in message[\\'content\\'] -%}\\n            {%- if item[\\'type\\'] == \\'image\\' -%}\\n                {{ \\'<start_of_image>\\' }}\\n            {%- elif item[\\'type\\'] == \\'text\\' -%}\\n                {%- set content = item[\\'text\\'] -%}\\n                {%- if \\'</think>\\' in content -%}\\n                    {%- set content = content.split(\\'</think>\\')[-1] -%}\\n                {%- endif -%}\\n                {{ content | trim }}\\n            {%- endif -%}\\n        {%- endfor -%}\\n    {%- else -%}\\n        {{ raise_exception(\"Invalid content type\") }}\\n    {%- endif -%}\\n\\n    {#- Tool response end tag -#}\\n    {%- if (message[\\'role\\'] == \\'tool\\') -%}\\n        {{ \\'</tool_response>\\' -}}\\n    {%- endif -%}\\n\\n    {#- Mark end of a single turn -#}\\n    {{ \\'<end_of_turn>\\\\n\\' }}\\n{%- endfor -%}\\n\\n{#- If generation is to be triggered, add model prompt prefix -#}\\n{%- if add_generation_prompt -%}\\n    {{\\'<start_of_turn>model\\\\n\\'}}\\n    {%- if enable_thinking is defined and enable_thinking is true -%}\\n        {{- \\'<think>\\' -}}\\n    {%- endif %}\\n{%- endif -%}',\n",
              "   'stop': ['<end_of_turn>'],\n",
              "   'bos_token': '<bos>',\n",
              "   'eos_token': '<end_of_turn>'}},\n",
              " {'id': 'togethercomputer/m2-bert-80M-2k-retrieval',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1699985626,\n",
              "  'type': <ModelType.EMBEDDING: 'embedding'>,\n",
              "  'display_name': 'M2-BERT-Retrieval-2K',\n",
              "  'organization': 'Together',\n",
              "  'license': 'Apache-2',\n",
              "  'pricing': {'input': 0.008,\n",
              "   'output': 0.008,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'togethercomputer/m2-bert-80M-32k-retrieval',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1699120644,\n",
              "  'type': <ModelType.EMBEDDING: 'embedding'>,\n",
              "  'display_name': 'M2-BERT-Retrieval-32k',\n",
              "  'organization': 'Together',\n",
              "  'link': 'https://huggingface.co/togethercomputer/m2-bert-80M-32k-retrieval',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.008,\n",
              "   'output': 0.008,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'togethercomputer/m2-bert-80M-8k-retrieval',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1699120644,\n",
              "  'type': <ModelType.EMBEDDING: 'embedding'>,\n",
              "  'display_name': 'M2-BERT-Retrieval-8k',\n",
              "  'organization': 'Together',\n",
              "  'link': 'https://huggingface.co/togethercomputer/m2-bert-80M-8k-retrieval',\n",
              "  'license': 'apache-2.0',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.008,\n",
              "   'output': 0.008,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'togethercomputer/MoA-1',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1733856970,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Together AI MoA-1',\n",
              "  'organization': 'Together AI',\n",
              "  'link': 'https://github.com/togethercomputer/MoA',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'togethercomputer/MoA-1-Turbo',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 0,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Together AI MoA-1-Turbo',\n",
              "  'organization': 'Together AI',\n",
              "  'link': 'https://github.com/togethercomputer/MoA',\n",
              "  'context_length': 32768,\n",
              "  'pricing': {'input': 0.0,\n",
              "   'output': 0.0,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}},\n",
              " {'id': 'togethercomputer/Refuel-Llm-V2',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1747260038,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Refuel LLM V2',\n",
              "  'organization': 'Refuel AI',\n",
              "  'link': 'https://huggingface.co/api/models/togethercomputer/refuel-llm-v2',\n",
              "  'license': 'cc-by-nc-4.0',\n",
              "  'context_length': 16384,\n",
              "  'pricing': {'input': 0.6,\n",
              "   'output': 0.6,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': ['</s>'],\n",
              "   'bos_token': '<s>',\n",
              "   'eos_token': '</s>'}},\n",
              " {'id': 'togethercomputer/Refuel-Llm-V2-Small',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1747174868,\n",
              "  'type': <ModelType.CHAT: 'chat'>,\n",
              "  'display_name': 'Refuel LLM V2 Small',\n",
              "  'organization': 'Refuel AI',\n",
              "  'link': 'https://huggingface.co/api/models/togethercomputer/refuel-llm-v2-small',\n",
              "  'context_length': 8192,\n",
              "  'pricing': {'input': 0.2,\n",
              "   'output': 0.2,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% else %}{{ eos_token }}{% endif %}\",\n",
              "   'stop': ['<|end_of_text|>'],\n",
              "   'bos_token': '<|begin_of_text|>',\n",
              "   'eos_token': '<|end_of_text|>'}},\n",
              " {'id': 'WhereIsAI/UAE-Large-V1',\n",
              "  'object': <ObjectType.Model: 'model'>,\n",
              "  'created': 1703216381,\n",
              "  'type': <ModelType.EMBEDDING: 'embedding'>,\n",
              "  'display_name': 'UAE-Large-V1',\n",
              "  'organization': 'WhereIsAI',\n",
              "  'link': 'https://huggingface.co/bert-base-uncased',\n",
              "  'license': 'apache-2.0',\n",
              "  'pricing': {'input': 0.016,\n",
              "   'output': 0.016,\n",
              "   'hourly': 0.0,\n",
              "   'base': 0.0,\n",
              "   'finetune': 0.0},\n",
              "  'running': False,\n",
              "  'config': {'chat_template': None,\n",
              "   'stop': [],\n",
              "   'bos_token': None,\n",
              "   'eos_token': None}}]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csv_or_excel(file_path):\n",
        "    try:\n",
        "        if file_path.endswith(\".csv\"):\n",
        "            df = pd.read_csv(file_path)\n",
        "        else:\n",
        "            df = pd.read_excel(file_path)\n",
        "        return df, df.head().to_string()\n",
        "    except Exception as e:\n",
        "        return None, f\"Error reading spreadsheet: {e}\"\n"
      ],
      "metadata": {
        "id": "6ZLeQ_aH6dlS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_text_or_doc(file_path):\n",
        "    if file_path.endswith(\".txt\"):\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        doc = docx.Document(file_path)\n",
        "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "    return \"\"\n"
      ],
      "metadata": {
        "id": "3sOtDrPg6f76"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() or \"\"\n",
        "    return text\n",
        "def load_image_text(file_path):\n",
        "    img = Image.open(file_path)\n",
        "    text = pytesseract.image_to_string(img)\n",
        "    return text"
      ],
      "metadata": {
        "id": "OIY_yr8i6lZg"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_visualization(df, query):\n",
        "    if \"correlation\" in query:\n",
        "        sns.heatmap(df.corr(), annot=True)\n",
        "        plt.show()\n",
        "    elif \"histogram\" in query:\n",
        "        num_cols = df.select_dtypes(include='number').columns\n",
        "        df[num_cols].hist(figsize=(10, 6))\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "MuhWGl5q6n2F"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_llm(question, context):\n",
        "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "    response = together.Complete.create(\n",
        "        prompt=prompt,\n",
        "        model=\"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
        "        max_tokens=300,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.7,\n",
        "        repetition_penalty=1.1,\n",
        "    )\n",
        "\n",
        "    print(\"🔍 Raw Response:\\n\", response)\n",
        "    return response['choices'][0]['text'].strip()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kdXw7GUE6r67"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import docx\n",
        "import pytesseract\n",
        "import fitz\n",
        "import pdfplumber\n",
        "from PIL import Image\n",
        "\n",
        "def extract_text_from_file(file_path):\n",
        "    ext = file_path.split('.')[-1].lower()\n",
        "\n",
        "    if ext == 'csv':\n",
        "        df = pd.read_csv(file_path)\n",
        "        return df, df.head().to_string()\n",
        "\n",
        "    elif ext == 'xlsx':\n",
        "        df = pd.read_excel(file_path)\n",
        "        return df, df.head().to_string()\n",
        "\n",
        "    elif ext == 'txt':\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return None, f.read()\n",
        "\n",
        "    elif ext == 'docx':\n",
        "        doc = docx.Document(file_path)\n",
        "        full_text = '\\n'.join([para.text for para in doc.paragraphs])\n",
        "        return None, full_text\n",
        "\n",
        "    elif ext == 'pdf':\n",
        "        text = ''\n",
        "        with pdfplumber.open(file_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text() or ''\n",
        "        return None, text\n",
        "\n",
        "    elif ext in ['png', 'jpg', 'jpeg']:\n",
        "        image = Image.open(file_path)\n",
        "        text = pytesseract.image_to_string(image)\n",
        "        return None, text\n",
        "\n",
        "    else:\n",
        "        return None, \"Unsupported file type\"\n"
      ],
      "metadata": {
        "id": "u4kRJ23662Nz"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "file_path = next(iter(uploaded))\n",
        "df, file_text = extract_text_from_file(file_path)\n",
        "if df is not None:\n",
        "    display(df.head())\n",
        "else:\n",
        "    print(file_text[:1000])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "uNpyxcUT65De",
        "outputId": "9900231d-b34b-4b3f-813d-69f901501f47"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e80f0573-92fb-452e-b5ae-394fc4aa7b7c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e80f0573-92fb-452e-b5ae-394fc4aa7b7c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Ayush_Kumar_Yadav_Resume_compressed.pdf to Ayush_Kumar_Yadav_Resume_compressed.pdf\n",
            "AYUSH KUMAR YADAV\n",
            "AI/ML Engineer | Data Scientist | Software Developer\n",
            "ay881009@gmail.com | +91 9370461604 | linkedin.com/in/Ayush-Kumar-Yadav |\n",
            "github.com/ayush-kumar-yadav\n",
            "PROFESSIONAL SUMMARY\n",
            "AI/ML Engineer with expertise in Deep Learning, NLP, Computer Vision, and MLOps. Built 8+\n",
            "production-grade AI systems with 95%+ accuracy, sub-200ms latency, and 99.9% uptime. Proficient\n",
            "in TensorFlow, PyTorch, Transformers, and building scalable ML pipelines using cloud and\n",
            "containerized deployments.\n",
            "EDUCATION\n",
            "Bachelor of Technology – Computer Science Engineering\n",
            "VIT-AP University, Vijayawada | Aug 2023 – July 2027\n",
            "Relevant Coursework: Machine Learning, Deep Learning, Algorithms, Data Structures, Big Data,\n",
            "Statistics\n",
            "TECHNICAL SKILLS\n",
            "• Programming: Python, R, SQL, Java, JavaScript, HTML/CSS\n",
            "• AI/ML: TensorFlow, PyTorch, Scikit-learn, Hugging Face Transformers\n",
            "• Deep Learning: CNNs, RNNs, Transformers (BERT, GPT, T5), LoRA Fine-tuning\n",
            "• Computer Vision: YOLO, OpenCV, Grad-CAM, GANs, Image Segmen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = input(\"Enter file path: \")\n",
        "df, file_text = extract_text_from_file(file_path)\n",
        "\n",
        "question = input(\"Enter your question for the agent: \")\n",
        "response = ask_llm(question=question, context=file_text)\n",
        "print(\"LLM Response:\\n\", response)\n",
        "\n",
        "if df is not None:\n",
        "    show_visualization(df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tlcn6Dn7C7P",
        "outputId": "41dd5c27-a5e5-4be9-93d4-e9c5d4b940d7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter file path: \"C:\\Users\\ASUS\\Downloads\\Ayush_Kumar_Yadav_Resume_compressed.pdf\"\n",
            "Enter your question for the agent: explain this document\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-2514855155>:4: DeprecationWarning: Call to deprecated function create.\n",
            "  response = together.Complete.create(\n",
            "/usr/local/lib/python3.11/dist-packages/together/legacy/complete.py:23: UserWarning: The use of together.api_key is deprecated and will be removed in the next major release. Please set the TOGETHER_API_KEY environment variable instead.\n",
            "  warnings.warn(API_KEY_WARNING)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Raw Response:\n",
            " {'id': 'nxvbiAf-28Eivz-94efa50cceee4aa6', 'object': <ObjectType.Completion: 'text.completion'>, 'created': 1749797333, 'model': 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', 'choices': [{'index': 0, 'finish_reason': <FinishReason.StopSequence: 'stop'>, 'text': ' I don\\'t have a document to explain. It seems there was an issue uploading or accessing the document, as indicated by \"Unsupported file type.\" If you can provide more context or details about the document you\\'re trying to share, I\\'d be happy to help in any way I can.'}], 'prompt': [], 'usage': {'prompt_tokens': 15, 'completion_tokens': 56, 'total_tokens': 71}}\n",
            "LLM Response:\n",
            " I don't have a document to explain. It seems there was an issue uploading or accessing the document, as indicated by \"Unsupported file type.\" If you can provide more context or details about the document you're trying to share, I'd be happy to help in any way I can.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def show_visualization(df):\n",
        "    print(\"Generating Correlation Heatmap...\")\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "    plt.title(\"Correlation Heatmap\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "w6UxKJYb7NMn"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_multiple_files(files, question):\n",
        "    if not files:\n",
        "        return \"No files uploaded.\", None\n",
        "\n",
        "    combined_text = \"\"\n",
        "    first_df = None\n",
        "    for file in files:\n",
        "        df, content = extract_text_from_file(file)\n",
        "        if isinstance(content, str):\n",
        "            combined_text += f\"\\n--- From {file.name} ---\\n{content}\\n\"\n",
        "        if df is not None and first_df is None:\n",
        "            first_df = df\n",
        "\n",
        "    response = ask_llm(question, combined_text)\n",
        "\n",
        "    heatmap_path = None\n",
        "    if first_df is not None:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.heatmap(first_df.corr(), annot=True, cmap=\"coolwarm\")\n",
        "        plt.title(\"Correlation Heatmap from First Data File\")\n",
        "        heatmap_path = \"heatmap_multi.png\"\n",
        "        plt.savefig(heatmap_path)\n",
        "        plt.close()\n",
        "\n",
        "    return response, heatmap_path\n"
      ],
      "metadata": {
        "id": "hnegYpO7AnKx"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 📚 Multi-Document AI Analyst\")\n",
        "    file_input = gr.File(label=\"Upload multiple documents\", file_types=[\".pdf\", \".docx\", \".txt\", \".csv\", \".xlsx\", \".png\", \".jpg\", \".jpeg\"], file_count=\"multiple\")\n",
        "    question_input = gr.Textbox(label=\"Ask a question about the uploaded documents\")\n",
        "    ask_btn = gr.Button(\"Analyze\")\n",
        "\n",
        "    llm_output = gr.Textbox(label=\"LLM Response\")\n",
        "    heatmap_output = gr.Image(label=\"Correlation Heatmap (if data file present)\")\n",
        "\n",
        "    ask_btn.click(fn=handle_multiple_files,\n",
        "                  inputs=[file_input, question_input],\n",
        "                  outputs=[llm_output, heatmap_output])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "duS92K_KAY_C",
        "outputId": "376ab2df-abfa-4e12-83de-69cd09a945f5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7470feee4e256d9a4f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7470feee4e256d9a4f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}